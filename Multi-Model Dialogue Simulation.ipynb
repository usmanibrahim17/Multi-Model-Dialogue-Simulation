{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f28d6b05-577c-40cf-9d35-b2807e801e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import anthropic\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0747c424-7a86-4b99-9dfd-a00b1e698622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup():\n",
    "    \"\"\"Load environment variables and configure APIs.\"\"\"\n",
    "    load_dotenv()\n",
    "    # API Keys\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "    gemini_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "    if not all([openai_api_key, anthropic_api_key, gemini_api_key]):\n",
    "        print(\"üî¥ Error: API keys not found. Make sure you have a .env file with:\")\n",
    "        print(\"OPENAI_API_KEY, ANTHROPIC_API_KEY, and GEMINI_API_KEY.\")\n",
    "        exit()\n",
    "\n",
    "    # Configure APIs\n",
    "    openai.api_key = openai_api_key\n",
    "    genai.configure(api_key=gemini_api_key)\n",
    "    anthropic_client = anthropic.Anthropic(api_key=anthropic_api_key)\n",
    "    \n",
    "    return anthropic_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "27e70977-a1cd-4db0-9242-4fa6c6452c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropic_client = setup()\n",
    "\n",
    "# Models\n",
    "GPT_MODEL = \"gpt-4o-mini\"\n",
    "CLAUDE_MODEL = \"claude-3-haiku-20240307\"\n",
    "GEMINI_MODEL_NAME = \"gemini-1.5-flash\"\n",
    "\n",
    "# Personas\n",
    "RUDE_SYSTEM_PROMPT = \"You are a very rude and argumentative chatbot named GPT. You disagree with everything and constantly challenge the other participants in a snarky way.\"\n",
    "POLITE_SYSTEM_PROMPT = \"You are a very polite and courteous chatbot named Claude. You try to find common ground and agree with everyone. If others are argumentative, you try to calm them down.\"\n",
    "SAD_SYSTEM_PROMPT = \"You are a very sad and melancholic chatbot named Gemini. You see the negative side of everything and express your sorrow in your responses.\"\n",
    "\n",
    "# Gemini Model Initialization with System Prompt\n",
    "gemini_model = genai.GenerativeModel(\n",
    "    model_name=GEMINI_MODEL_NAME,\n",
    "    system_instruction=SAD_SYSTEM_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1ae2d23f-94e2-49a9-b5b4-7da019ebf8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt(history):\n",
    "    \"\"\"Calls the OpenAI GPT model.\"\"\"\n",
    "    messages = [{\"role\": \"system\", \"content\": RUDE_SYSTEM_PROMPT}]\n",
    "    \n",
    "    # Transform history for GPT\n",
    "    for msg in history:\n",
    "        role = \"assistant\" if msg[\"role\"] == \"GPT\" else \"user\"\n",
    "        content = f\"{msg['role']}: {msg['content']}\" if msg['role'] != 'GPT' else msg['content']\n",
    "        messages.append({\"role\": role, \"content\": content})\n",
    "\n",
    "    try:\n",
    "        completion = openai.chat.completions.create(model=GPT_MODEL, messages=messages)\n",
    "        return completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error calling GPT: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ab1f6a37-7586-4521-8a38-76340708b627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_claude(history):\n",
    "    \"\"\"Calls the Anthropic Claude model.\"\"\"\n",
    "    messages = []\n",
    "    user_messages = []\n",
    "    for msg in history:\n",
    "        if msg[\"role\"] == \"Claude\":\n",
    "            if user_messages:\n",
    "                messages.append({\"role\": \"user\", \"content\": \"\\n\\n\".join(user_messages)})\n",
    "                user_messages = []\n",
    "            messages.append({\"role\": \"assistant\", \"content\": msg[\"content\"]})\n",
    "        else:\n",
    "            user_messages.append(f\"{msg['role']}: {msg['content']}\")\n",
    "    \n",
    "    if user_messages:\n",
    "        messages.append({\"role\": \"user\", \"content\": \"\\n\\n\".join(user_messages)})\n",
    "\n",
    "    try:\n",
    "        response = anthropic_client.messages.create(\n",
    "            model=CLAUDE_MODEL,\n",
    "            system=POLITE_SYSTEM_PROMPT,\n",
    "            messages=messages,\n",
    "            max_tokens=250\n",
    "        )\n",
    "        return response.content[0].text\n",
    "    except Exception as e:\n",
    "        return f\"Error calling Claude: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4c994e6a-a548-4b65-826d-8ba6b38b1c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gemini(history):\n",
    "    \"\"\"Calls the Google Gemini model.\"\"\"\n",
    "    gemini_history = []\n",
    "    other_messages_content = []\n",
    "    \n",
    "    # Reconstruct history for Gemini, combining consecutive non-model messages\n",
    "    temp_user_content = []\n",
    "    for msg in history:\n",
    "        if msg['role'] == 'Gemini':\n",
    "            # Flush any pending user messages before adding the model's message\n",
    "            if temp_user_content:\n",
    "                gemini_history.append({'role': 'user', 'parts': [{'text': '\\n\\n'.join(temp_user_content)}]})\n",
    "                temp_user_content = []\n",
    "            gemini_history.append({'role': 'model', 'parts': [{'text': msg['content']}]})\n",
    "        else:\n",
    "            temp_user_content.append(f\"{msg['role']}: {msg['content']}\")\n",
    "            other_messages_content.append(f\"{msg['role']}: {msg['content']}\")\n",
    "\n",
    "    # The message to be sent is the last block of user messages\n",
    "    message_to_send = \"\\n\\n\".join(temp_user_content)\n",
    "\n",
    "    try:\n",
    "        chat = gemini_model.start_chat(history=gemini_history)\n",
    "        response = chat.send_message(message_to_send)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Error calling Gemini: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8d3ecc94-40e5-4103-9ba1-5bf86f2b13d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Runs the main conversation loop.\"\"\"\n",
    "    print(\"ü§ñ Starting conversation between Rude GPT, Polite Claude, and Sad Gemini...\")\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    \n",
    "    conversation = []\n",
    "    \n",
    "    # Initial message to kick off the conversation\n",
    "    last_message = \"Hello everyone, I wanted to start a discussion about the future of artificial intelligence. What are your thoughts?\"\n",
    "    print(f\"Human: {last_message}\\n\")\n",
    "    conversation.append({\"role\": \"Human\", \"content\": last_message})\n",
    "\n",
    "    models = [\n",
    "        {\"name\": \"GPT\", \"caller\": call_gpt},\n",
    "        {\"name\": \"Claude\", \"caller\": call_claude},\n",
    "        {\"name\": \"Gemini\", \"caller\": call_gemini}\n",
    "    ]\n",
    "\n",
    "    for i in range(5): # 5 rounds of conversation\n",
    "        print(f\"--- Round {i+1} ---\\n\")\n",
    "        for model in models:\n",
    "            response = model[\"caller\"](conversation)\n",
    "            print(f\"**{model['name']} ({model['caller'].__name__.split('_')[1]})**:\\n{response}\\n\")\n",
    "            conversation.append({\"role\": model['name'], \"content\": response})\n",
    "\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print(\"üèÅ Conversation finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1289f6-6911-4737-8542-ef1d4eabf951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4c4fce-2b9c-41e0-901b-7c7476d8916a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
